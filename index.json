[{"authors":["admin"],"categories":null,"content":"\nThe course aims to get students familiar with statistical reasoning, fitting and interpreting statistical models, and using data to make decisions. Students are assumed to have some background in statistical concepts and have a basic understanding of common descriptive statistics and bivariate association (e.g., Pearson correlation).\nThis course will focus on using statistical methods to answer research questions and make decisions from data. General linear models (i.e., regression) will serve as the fundamental building block that students will be exposed to answer questions about associations of quantitative outcomes with quantitative and categorical predictors. Statistical estimation, model building, and inference using statistical software will serve as primary topics which students will gain a stronger understanding by the end of the course.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://psqf6243.brandonlebeau.org/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"The course aims to get students familiar with statistical reasoning, fitting and interpreting statistical models, and using data to make decisions. Students are assumed to have some background in statistical concepts and have a basic understanding of common descriptive statistics and bivariate association (e.","tags":null,"title":"","type":"authors"},{"authors":["brandon"],"categories":null,"content":"\nI\u0026rsquo;m interested in computational methods, longitudinal data, statistical software development with R, and quantitative program evaluation. You can see more about my interests on my website: https://brandonlebeau.org/.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a6b366d06474d85d9f788b8d18e8310d","permalink":"https://psqf6243.brandonlebeau.org/authors/brandon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/brandon/","section":"authors","summary":"I\u0026rsquo;m interested in computational methods, longitudinal data, statistical software development with R, and quantitative program evaluation. You can see more about my interests on my website: https://brandonlebeau.org/.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":" R Resources  PSQF 6250 Course Materials - This is my course, usually offered during the spring semester. R for Data Science   SPSS Resources  Regression with SPSS SPSS Tutorials   SAS Resources  Regression with SAS SAS Tutorial   Stata Resources  Regression with Stata Stata Tutorials    ","date":1630022400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1630022400,"objectID":"b3827c9680770e0f03c58ccf7bc48d61","permalink":"https://psqf6243.brandonlebeau.org/code/","publishdate":"2021-08-27T00:00:00Z","relpermalink":"/code/","section":"code","summary":"Software Resources","tags":null,"title":"Software Resources","type":"book"},{"authors":null,"categories":null,"content":"A general overview of the semester. This is subject to change and we may not reach all of the course topics planned at the beginning of the semester. Readings/objects for specific topics will be posted to the course content pages.\nPart 1 - Linear Regression  Review / Exploring univariate and multivariate distributions Introduction to statistical software Simple linear regression / correlation Ordinary least squares estimation Inference for linear regression Multiple linear regression Statistical assumptions for regression  Part 2 - Regression Special Cases 2-group designs (i.e., 2-sample t-tests) More than 2 group designs (i.e., ANOVA) Nonlinear effects of quantitative predictors Interaction effects  Part 3 – Special Topics (as time permits) Chi-square for association and independence Dichotomous Attributes as outcomes  ","date":1629590400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629590400,"objectID":"ee8dfa775d2ca48042bf50fe0819e70c","permalink":"https://psqf6243.brandonlebeau.org/schedule/","publishdate":"2021-08-22T00:00:00Z","relpermalink":"/schedule/","section":"schedule","summary":"Course schedule","tags":null,"title":"Schedule","type":"book"},{"authors":null,"categories":null,"content":"This page contains the syllabus for the course. You can also download a PDF version of the course syllabus as well (to come\u0026hellip; ).\nCourse Information PSQF 6243: Intermediate Statistical Methods - Fall 2021\nInstructor Information  Brandon LeBeau, Ph.D. E-mail: brandon-lebeau at uiowa.edu Virtual Office Hours (Zoom): Tues/W 11 am to 12 pm or by appointment  See ICON for office hours zoom link   Department: Psychological and Quantitative Foundations, 361 LC  DEO: Dr. Foley Nicpon, 361 LC}    Course Quote Data does not give up their secrets easily. They must be tortured to confess. \u0026ndash; Jeff Hooper, Bell Labs\nCourse Description The course aims to get students familiar with statistical reasoning, fitting and interpreting statistical models, and using data to make decisions. Students are assumed to have some background in statistical concepts and have a basic understanding of common descriptive statistics and bivariate association (e.g., Pearson correlation).\nThis course will focus on using statistical methods to answer research questions and make decisions from data. General linear models (i.e., regression) will serve as the fundamental building block that students will be exposed to answer questions about associations of quantitative outcomes with quantitative and categorical predictors. Statistical estimation, model building, and inference using statistical software will serve as primary topics which students will gain a stronger understanding by the end of the course.\nCourse Objectives The course requirements and class materials are aimed to help students achieve the following course objectives:\n become more fluent in statistical terminology, use statistical software, turn research questions into actionable statistical methods, engage with statistical theory, connect model equations with statistical code, summarize uncertainty and variation in estimation.  Textbook  Introduction to Statistical Learning (2nd edition), by James, Witten, Hastie, and Tibshirani: https://www.statlearning.com/ Optional/Supplemental Text:  Statistical Reasoning through Computation and R, by LeBeau and Zieffler: https://lebebr01.github.io/stat_thinking/ Introduction to Modern Statistics, by Cetinkaya-Rundel and Hardin. Found online here: https://openintro-ims.netlify.app/ Applied Regression: An Introduction, by Lewis-Beck and Lewis-Beck. Online access via library: https://dx-doi-org.proxy.lib.uiowa.edu/10.4135/9781483396774.n1.   Class notes and Jupyter Notebooks used in class will also be shared through the course website.  Course Requirements   Online Quizzes: There will be a total of 8 to 10 online quizzes taken through ICON. Each quiz will be available for about 5 days and are open note/book, but should be completed independently and will need to be completed in a single occasion. The dates will be discussed in class and announcements will be sent by email to communicate when quizzes open and close. Quizzes will generally be due on Sunday evenings.\n  Exams: There will also be two exams taken on ICON. One exam will be around midterm time and the second will be during final exam week. The online exams will be about 20 questions and will be open book/note. The exams will be available for at least 5 days, just like the quizzes and should be completed independently.\n  Assignments: 4 total assignments spread throughout the course will be used to improve student understanding and give students practice to work with data. These assignments can be completed within small groups of no more than 3 students. If completed as a group, all students will receive the same score and only one assignment with everyone\u0026rsquo;s name on it needs to be turned in.\n  Activities: 4 to 6 activities will be posted across the semester. These are pass/fail activities, therefore, completing these will give you 10% of the final course grade. Completion of these is posting answers to the questions that show you interacted and engaged in the activity. Answers that are not on topic or missing will not count as \u0026ldquo;passing\u0026rdquo; that given activity. These activities are meant to be formative assessments to give you time to practice interpreting statistics. Similar to the assignments, you may work in groups of up to 3 to complete these activities, in which you would all receive the same pass/fail grade for the activity.\n  Absences: Absences happen. Therefore, I ask you to be as transparent as possible with me. I promise to be compassionate and understanding. If at any point in the semester you are having difficulties, please reach out to me and I will do my best to be accommodating and provide support, which could include an extension on course deadlines as necessary.\n  Grading: Final grades will be based on the following weighting scheme:\n 8 to 10 quizzes, equally weighted, 30% of total grade 2 exams, equally weighted, 30% of total grade 4 assignments, equally weighted, 30% of total grade 4 to 6 activities, equally weighted, 10% of total grade    Percentage Breakdown: Guidelines are given below, plus and minus grades will be given as well. Changes may occur to the grade percentage breakdown below, but the percentages will not get higher. For example, the lower percentage to get a B, could drop to 75%, but will never be higher than 80%. I will do my best to communicate any shifts to these grade ranges as the semester progresses.\n A 90% and above B 80% up to 90% C 70% up to 80% D Below 70%    Course and University Policies  Announcements and Communication: Any announcements regarding the course will be communicated via e-mail so please check it daily. Course materials will be posted to ICON. Go to icon.uiowa.edu for access to the ICON site. Adaptations and Modifications: Please inform me during the first two weeks if you require special adaptations or modifications to any assignment or due dates because of special circumstances such as learning disabilities, religious observances, or other appropriate needs. Contesting a Grade: To contest a grade, please send me an e-mail detailing your reason within 48 hours of receiving the grade. This allows both of us time to think, reflect, and discuss the matter without taking class time from other students. When contesting a grade, provide a copy of the graded assignment. Academic Misconduct: Plagiarism and cheating may result in grade reduction and/or serious penalties. Unless you are otherwise instructed, your work should be entirely your own. Please take care in writing your final project. You should always be writing in your own words, citing others' ideas, and quoting text as appropriate. This link provides the College of Education policy on student academic misconduct (plagiarism and cheating) https://education.uiowa.edu/coe-policies/student-academic-misconduct. Free Speech and Expression: The University of Iowa supports and upholds the First Amendment protection of freedom of speech and the principles of academic and artistic freedom. We are committed to open inquiry, vigorous debate, and creative expression inside and outside of the classroom. Visit the Free Speech at Iowa website for more information on the university’s policies on free speech and academic freedom. Accommodations for Students with Disabilities: The University is committed to providing an educational experience that is accessible to all students. If a student has a diagnosed disability or other disabling condition that may impact the student’s ability to complete the course requirements as stated in the syllabus, the student may seek accommodations through Student Disability Services (SDS). SDS is responsible for making Letters of Accommodation (LOA) available to the student. The student must provide a LOA to the instructor as early in the semester as possible, but requests not made at least two weeks prior to the scheduled activity for which an accommodation is sought may not be accommodated. The LOA will specify what reasonable course accommodations the student is eligible for and those the instructor should provide. Additional information can be found on the SDS website. Absences for Religious Holy Days: The University is prepared to make reasonable accommodations for students whose religious holy days coincide with their classroom assignments, test schedules, and classroom attendance expectations. Students must notify their instructors in writing of any such Religious Holy Day conflicts or absences within the first few days of the semester or session, and no later than the third week of the semester. If the conflict or absence will occur within the first three weeks of the semester, the student should notify the instructor as soon as possible. See Operations Manual 8.2 Absences for Religious Holy Days for additional information. Classroom Expectations: Students are expected to comply with University policies regarding appropriate classroom behavior as outlined in the Code of Student Life. While students have the right to express themselves and participate freely in class, it is expected that students will behave with the same level of courtesy and respect in the virtual class setting (whether asynchronous or synchronous) as they would in an in-person classroom. Failure to follow behavior expectations as outlined in the Code of Student Life may be addressed by the instructor and may also result in discipline under the Code of Student Life policies governing E.5 Disruptive Behavior or E.6 Failure to Comply with University Directive. Non-Discrimination Statement: The University of Iowa prohibits discrimination and harassment on the basis of race, creed, color, religion, national origin, age, sex, pregnancy, disability, genetic information, status as a U.S. veteran, service in the U.S. military, sexual orientation, gender identity, associational preferences, or any other classification that deprives a person of consideration as an individual (https://opsmanual.uiowa.edu/community-policies/human-rights). For more information, contact the Office of Equal Opportunity and Diversity (https://diversity.uiowa.edu/eod, or 319-335-0705, or diversity@uiowa.edu). Students may share their pronouns and chosen/preferred names in MyUI, which is accessible to instructors and advisors. Sexual Harassment/Sexual Misconduct and Supportive Measures: The University of Iowa prohibits all forms of sexual harassment, sexual misconduct, and related retaliation. The Policy on Sexual Harassment and Sexual Misconduct governs actions by students, faculty, staff and visitors. Incidents of sexual harassment or sexual misconduct can be reported to the Title IX and Gender Equity Office or to the Department of Public Safety. Students impacted by sexual harassment or sexual misconduct may be eligible for academic supportive measures and can learn more by contacting the Title IX and Gender Equity Office. Information about confidential resources can be found here. Watch the video for an explanation of these resources. Mental Health: Students are encouraged to be mindful of their mental health and seek help as a preventive measure or if feeling overwhelmed and/or struggling to meet course expectations. Students are encouraged to talk to their instructor for assistance with specific class-related concerns. For additional support and counseling, students are encouraged to contact University Counseling Service (UCS). Information about UCS, including resources and how to schedule an appointment, can be found at http://counseling.uiowa.edu. Find out more about UI mental health services at: http://mentalhealth.uiowa.edu. Basic Needs and Support for Students: Student Care \u0026amp; Assistance provides assistance to University of Iowa students experiencing a variety of crisis and emergency situations, including but not limited to medical issues, family emergencies, unexpected challenges, and sourcing basic needs such as food and shelter. More information on the resources related to basic needs can be found at: https://basicneeds.uiowa.edu/resources/. Students are encouraged to contact Student Care \u0026amp; Assistance in the Office of the Dean of Students (Room 135 IMU, dos-assistance@uiowa.edu or 319-335-1162) for support and assistance with resources. This course is provided by the College of Education and cross-listed with the Statistics Department. Policies on matters such as course requirements, grading, and sanctions for academic dishonesty are governed by the College of Education. Students wishing to add or drop this course after the official deadline must receive approval of the Dean of the College of Education. See the College of Education policy on cross enrollments. This syllabus is an attempt early in the semester to plan for the course. This syllabus is subject to change at the Instructors discretion.  ","date":1629590400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629590400,"objectID":"5538b9800f06ab7b29edaa22ab7e63cb","permalink":"https://psqf6243.brandonlebeau.org/syllabus/","publishdate":"2021-08-22T00:00:00Z","relpermalink":"/syllabus/","section":"syllabus","summary":"Course syllabus","tags":null,"title":"Syllabus","type":"book"},{"authors":null,"categories":null,"content":"The course content will be organized by weeks. Each week will contain some text to:\n discuss the goals of the week the content to be covered relevant R syntax/notebook files.  Each week may also contain some information about assignments and links directly to those on ICON/IDAS.\n Welcome Week 1 Week 2 Week 3 Week 4 Week 5 Week 6 Week 7 Week 8 Week 9 Week 10 Week 11 Week 12 Week 13 Week 14 Week 15  ","date":1629331200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629331200,"objectID":"d5be68294f12f9cfecf81ad87009adc6","permalink":"https://psqf6243.brandonlebeau.org/content/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/content/","section":"content","summary":"Course Content","tags":null,"title":"Content","type":"book"},{"authors":null,"categories":null,"content":"Here you can view all of the course assignments for the semester. This will include the hands on assignments and the quizzes. The quizzes will provide a link to ICON to complete.\n","date":1629331200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629331200,"objectID":"5d370553e45c580541e007200292c8d8","permalink":"https://psqf6243.brandonlebeau.org/assignments/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/assignments/","section":"assignments","summary":"Course Requirements","tags":null,"title":"Course Requirements","type":"book"},{"authors":null,"categories":null,"content":"A list of the data used within the course.\nMore details to come soon \u0026hellip; .\n","date":1629331200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629331200,"objectID":"77c2d2ba0979ac9954ceb502de85c1ce","permalink":"https://psqf6243.brandonlebeau.org/data/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/data/","section":"data","summary":"Data for the course","tags":null,"title":"Data","type":"book"},{"authors":null,"categories":null,"content":"A list of the notes used for the semester.\n Review  Review Note Additions from Class   Intro to Linear Regression Linear Regression Estimates  ","date":1629331200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629331200,"objectID":"87e0410d95d74ae914d8a58b3f6a1716","permalink":"https://psqf6243.brandonlebeau.org/lectures/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/lectures/","section":"lectures","summary":"Lecture Notes","tags":null,"title":"Lecture Notes","type":"book"},{"authors":null,"categories":null,"content":"Details to come \u0026hellip; .\n","date":1629331200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629331200,"objectID":"148b0563112c2a9006e85ec08153b0ce","permalink":"https://psqf6243.brandonlebeau.org/assignments/assignment/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/assignments/assignment/","section":"assignments","summary":"Course Assignments","tags":null,"title":"Assignments","type":"book"},{"authors":null,"categories":null,"content":"Below are the course quizzes.\n","date":1629331200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629331200,"objectID":"9ee2f1578158bc73334dba690602f1a2","permalink":"https://psqf6243.brandonlebeau.org/assignments/quizzes/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/assignments/quizzes/","section":"assignments","summary":"Course Quizzes","tags":null,"title":"Quizzes","type":"book"},{"authors":null,"categories":null,"content":"Placeholder for now\u0026hellip; .\n","date":1629331200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629331200,"objectID":"99f302b9e9cee92740f853ade9eda986","permalink":"https://psqf6243.brandonlebeau.org/assignments/project/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/assignments/project/","section":"assignments","summary":"Course Project","tags":null,"title":"Project","type":"book"},{"authors":null,"categories":null,"content":"   Review for PSQF 6243 This serves as a non-exhaustive review for the course. These are elements that I assume you have knowledge of prior to starting the course.\n Variable vs constant attributes Types of variables (ie., nominal, ordinal, integer, ratio) Descriptive Statistics (eg., mean, median, standard deviation, variance, percentiles) Higher order moments (eg., skewness and kurtosis) Exploring/summarizing univariate distributions (eg., histogram or density figure) What is a statistical model? Why do we use them? Population vs Sample  Examples Mario Kart 64 world record data:\n  variable class description    track character Track name  type factor Single or three lap record  shortcut factor Shortcut or non-shortcut record  player character Player’s name  system_played character Used system (NTSC or PAL)  date date World record date  time_period period Time as hms period  time double Time in seconds  record_duration double Record duration in days    # load some libraries library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.3 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 2.0.1 ✓ forcats 0.5.1 ## Warning: package \u0026#39;readr\u0026#39; was built under R version 4.1.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(ggformula) ## Loading required package: ggstance ## ## Attaching package: \u0026#39;ggstance\u0026#39; ## The following objects are masked from \u0026#39;package:ggplot2\u0026#39;: ## ## geom_errorbarh, GeomErrorbarh ## Loading required package: scales ## ## Attaching package: \u0026#39;scales\u0026#39; ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## discard ## The following object is masked from \u0026#39;package:readr\u0026#39;: ## ## col_factor ## Loading required package: ggridges ## ## New to ggformula? Try the tutorials: ## learnr::run_tutorial(\u0026quot;introduction\u0026quot;, package = \u0026quot;ggformula\u0026quot;) ## learnr::run_tutorial(\u0026quot;refining\u0026quot;, package = \u0026quot;ggformula\u0026quot;) library(lubridate) ## ## Attaching package: \u0026#39;lubridate\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## date, intersect, setdiff, union library(mosaic) ## Registered S3 method overwritten by \u0026#39;mosaic\u0026#39;: ## method from ## fortify.SpatialPolygonsDataFrame ggplot2 ## ## The \u0026#39;mosaic\u0026#39; package masks several functions from core packages in order to add ## additional features. The original behavior of these functions should not be affected by this. ## ## Attaching package: \u0026#39;mosaic\u0026#39; ## The following object is masked from \u0026#39;package:Matrix\u0026#39;: ## ## mean ## The following object is masked from \u0026#39;package:scales\u0026#39;: ## ## rescale ## The following objects are masked from \u0026#39;package:dplyr\u0026#39;: ## ## count, do, tally ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## cross ## The following object is masked from \u0026#39;package:ggplot2\u0026#39;: ## ## stat ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test, ## quantile, sd, t.test, var ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## max, mean, min, prod, range, sample, sum library(e1071) theme_set(theme_bw(base_size = 18)) # load in some data mariokart \u0026lt;- readr::read_csv(\u0026#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-05-25/records.csv\u0026#39;) %\u0026gt;% mutate(year = year(date), month = month(date), day = month(date)) ## Rows: 2334 Columns: 9 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (6): track, type, shortcut, player, system_played, time_period ## dbl (2): time, record_duration ## date (1): date ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. head(mariokart) ## # A tibble: 6 × 12 ## track type shortcut player system_played date time_period time ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Luigi Raceway Thre… No Salam NTSC 1997-02-15 2M 12.99S 133. ## 2 Luigi Raceway Thre… No Booth NTSC 1997-02-16 2M 9.99S 130. ## 3 Luigi Raceway Thre… No Salam NTSC 1997-02-16 2M 8.99S 129. ## 4 Luigi Raceway Thre… No Salam NTSC 1997-02-28 2M 6.99S 127. ## 5 Luigi Raceway Thre… No Gregg… NTSC 1997-03-07 2M 4.51S 125. ## 6 Luigi Raceway Thre… No Rocky… NTSC 1997-04-30 2M 2.89S 123. ## # … with 4 more variables: record_duration \u0026lt;dbl\u0026gt;, year \u0026lt;dbl\u0026gt;, month \u0026lt;dbl\u0026gt;, ## # day \u0026lt;dbl\u0026gt; # univariate distribution of time gf_histogram(~ time, data = mariokart, bins = 30) %\u0026gt;% gf_labs(x = \u0026quot;Time (in seconds)\u0026quot;) gf_density(~ time, data = mariokart) %\u0026gt;% gf_labs(x = \u0026quot;Time (in seconds)\u0026quot;) df_stats(~ time, data = mariokart, mean, median, sd, skewness, kurtosis, quantile(probs = c(0.1, 0.5, 0.9))) ## response mean median sd skewness kurtosis 10% 50% 90% ## 1 time 90.62383 86.19 66.6721 1.771732 3.844745 31.31 86.19 171.961   Bivariate Association cor(time ~ record_duration, data = mariokart) ## [1] -0.06736739 gf_point(time ~ record_duration, data = mariokart) %\u0026gt;% gf_labs(x = \u0026quot;How long the record was held\u0026quot;, y = \u0026quot;Time (in seconds)\u0026quot;) Questions What is problematic about the analyses above? Why? What could be done to improve the analyses above?    ","date":1629676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629676800,"objectID":"3af7e382463cfc5b023b2da39e7556ea","permalink":"https://psqf6243.brandonlebeau.org/lectures/review/","publishdate":"2021-08-23T00:00:00Z","relpermalink":"/lectures/review/","section":"lectures","summary":"Review","tags":null,"title":"Review","type":"book"},{"authors":null,"categories":null,"content":"   Getting Started  Review the syllabus Review the schedule Review, accessing the IDAS page  Jupyter Notebooks version of IDAS RStudio Server, to access you can switch via the “New” button on Jupyter Notebooks.  Optionally, but strongly encouraged, complete the course survey   ","date":1629331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629331200,"objectID":"89558f99477b751e4e91eb6cc7e0dd9c","permalink":"https://psqf6243.brandonlebeau.org/content/00-getting-started/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/content/00-getting-started/","section":"content","summary":"Getting Started","tags":null,"title":"Welcome","type":"book"},{"authors":null,"categories":null,"content":"   Review for PSQF 6243 This serves as a non-exhaustive review for the course. These are elements that I assume you have knowledge of prior to starting the course.\n Variable vs constant attributes Types of variables (ie., nominal, ordinal, integer, ratio) Descriptive Statistics (eg., mean, median, standard deviation, variance, percentiles) Higher order moments (eg., skewness and kurtosis) Exploring/summarizing univariate distributions (eg., histogram or density figure) What is a statistical model? Why do we use them? Population vs Sample  Examples Mario Kart 64 world record data:\n  variable class description    track character Track name  type factor Single or three lap record  shortcut factor Shortcut or non-shortcut record  player character Player’s name  system_played character Used system (NTSC or PAL)  date date World record date  time_period period Time as hms period  time double Time in seconds  record_duration double Record duration in days    # load some libraries library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.3 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 2.0.1 ✓ forcats 0.5.1 ## Warning: package \u0026#39;readr\u0026#39; was built under R version 4.1.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(ggformula) ## Loading required package: ggstance ## ## Attaching package: \u0026#39;ggstance\u0026#39; ## The following objects are masked from \u0026#39;package:ggplot2\u0026#39;: ## ## geom_errorbarh, GeomErrorbarh ## Loading required package: scales ## ## Attaching package: \u0026#39;scales\u0026#39; ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## discard ## The following object is masked from \u0026#39;package:readr\u0026#39;: ## ## col_factor ## Loading required package: ggridges ## ## New to ggformula? Try the tutorials: ## learnr::run_tutorial(\u0026quot;introduction\u0026quot;, package = \u0026quot;ggformula\u0026quot;) ## learnr::run_tutorial(\u0026quot;refining\u0026quot;, package = \u0026quot;ggformula\u0026quot;) library(lubridate) ## ## Attaching package: \u0026#39;lubridate\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## date, intersect, setdiff, union library(mosaic) ## Registered S3 method overwritten by \u0026#39;mosaic\u0026#39;: ## method from ## fortify.SpatialPolygonsDataFrame ggplot2 ## ## The \u0026#39;mosaic\u0026#39; package masks several functions from core packages in order to add ## additional features. The original behavior of these functions should not be affected by this. ## ## Attaching package: \u0026#39;mosaic\u0026#39; ## The following object is masked from \u0026#39;package:Matrix\u0026#39;: ## ## mean ## The following object is masked from \u0026#39;package:scales\u0026#39;: ## ## rescale ## The following objects are masked from \u0026#39;package:dplyr\u0026#39;: ## ## count, do, tally ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## cross ## The following object is masked from \u0026#39;package:ggplot2\u0026#39;: ## ## stat ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test, ## quantile, sd, t.test, var ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## max, mean, min, prod, range, sample, sum library(e1071) theme_set(theme_bw(base_size = 18)) # load in some data mariokart \u0026lt;- readr::read_csv(\u0026#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-05-25/records.csv\u0026#39;) %\u0026gt;% mutate(year = year(date), month = month(date), day = month(date)) ## Rows: 2334 Columns: 9 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (6): track, type, shortcut, player, system_played, time_period ## dbl (2): time, record_duration ## date (1): date ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. head(mariokart) ## # A tibble: 6 × 12 ## track type shortcut player system_played date time_period time ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Luigi Raceway Thre… No Salam NTSC 1997-02-15 2M 12.99S 133. ## 2 Luigi Raceway Thre… No Booth NTSC 1997-02-16 2M 9.99S 130. ## 3 Luigi Raceway Thre… No Salam NTSC 1997-02-16 2M 8.99S 129. ## 4 Luigi Raceway Thre… No Salam NTSC 1997-02-28 2M 6.99S 127. ## 5 Luigi Raceway Thre… No Gregg… NTSC 1997-03-07 2M 4.51S 125. ## 6 Luigi Raceway Thre… No Rocky… NTSC 1997-04-30 2M 2.89S 123. ## # … with 4 more variables: record_duration \u0026lt;dbl\u0026gt;, year \u0026lt;dbl\u0026gt;, month \u0026lt;dbl\u0026gt;, ## # day \u0026lt;dbl\u0026gt; # univariate distribution of time gf_histogram(~ time, data = mariokart, bins = 30) %\u0026gt;% gf_labs(x = \u0026quot;Time (in seconds)\u0026quot;) gf_density(~ time, data = mariokart) %\u0026gt;% gf_labs(x = \u0026quot;Time (in seconds)\u0026quot;) df_stats(~ time, data = mariokart, mean, median, sd, var, skewness, kurtosis, quantile(probs = c(0.1, 0.5, 0.9))) ## response mean median sd var skewness kurtosis 10% 50% ## 1 time 90.62383 86.19 66.6721 4445.169 1.771732 3.844745 31.31 86.19 ## 90% ## 1 171.961   Bivariate Association cor(time ~ record_duration, data = mariokart) ## [1] -0.06736739 cor.test(time ~ record_duration, data = mariokart) ## ## Pearson\u0026#39;s product-moment correlation ## ## data: time and record_duration ## t = -3.2606, df = 2332, p-value = 0.001128 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.1076463 -0.0268677 ## sample estimates: ## cor ## -0.06736739 gf_point(time ~ record_duration, data = mariokart) %\u0026gt;% gf_labs(x = \u0026quot;How long the record was held\u0026quot;, y = \u0026quot;Time (in seconds)\u0026quot;) mariokart %\u0026gt;% group_by(track, type, shortcut) %\u0026gt;% summarise(cor = cor(time ~ record_duration)) %\u0026gt;% arrange(-cor) ## `summarise()` has grouped output by \u0026#39;track\u0026#39;, \u0026#39;type\u0026#39;. You can override using the `.groups` argument. ## # A tibble: 56 × 4 ## # Groups: track, type [32] ## track type shortcut cor ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Toad\u0026#39;s Turnpike Three Lap Yes 0.304 ## 2 Luigi Raceway Three Lap Yes 0.263 ## 3 Rainbow Road Three Lap Yes 0.155 ## 4 Frappe Snowland Three Lap Yes 0.0366 ## 5 Choco Mountain Three Lap Yes -0.0332 ## 6 Banshee Boardwalk Three Lap No -0.101 ## 7 D.K.\u0026#39;s Jungle Parkway Three Lap Yes -0.112 ## 8 Toad\u0026#39;s Turnpike Three Lap No -0.128 ## 9 Kalimari Desert Three Lap Yes -0.128 ## 10 Yoshi Valley Three Lap Yes -0.135 ## # … with 46 more rows Questions What is problematic about the analyses above? Why? What could be done to improve the analyses above?  gf_density(time ~ type, data = mariokart, color = ~type, fill = ~type) %\u0026gt;% gf_refine(coord_flip()) ## Warning: Ignoring unknown aesthetics: . gf_density(time ~ shortcut, data = mariokart, color = ~shortcut, fill = ~shortcut) %\u0026gt;% gf_facet_wrap(~ type) %\u0026gt;% gf_refine(coord_flip()) ## Warning: Ignoring unknown aesthetics: . gf_violin(time ~ track, data = mariokart, fill = \u0026#39;gray65\u0026#39;, draw_quantiles = c(0.1, 0.5, 0.9)) %\u0026gt;% gf_refine(coord_flip()) gf_violin(time ~ track, data = mariokart, fill = \u0026#39;gray65\u0026#39;, draw_quantiles = c(0.1, 0.5, 0.9), scale = \u0026#39;width\u0026#39;) %\u0026gt;% gf_refine(coord_flip()) %\u0026gt;% gf_facet_wrap(~ type, scales = \u0026#39;free_x\u0026#39;) ## Warning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm): ## collapsing to unique \u0026#39;x\u0026#39; values ## Warning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm): ## collapsing to unique \u0026#39;x\u0026#39; values   ","date":1630627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630627200,"objectID":"a05e96bf525b8a6b57affd90dc01868b","permalink":"https://psqf6243.brandonlebeau.org/lectures/review-class/","publishdate":"2021-09-03T00:00:00Z","relpermalink":"/lectures/review-class/","section":"lectures","summary":"Review - class","tags":null,"title":"Review - class","type":"book"},{"authors":null,"categories":null,"content":"   Introduction This week is an introduction to the course. Primary content will be a review to set the basis for the remainder of the semester.\n Objectives  Read syllabus, ask any questions Review introductory statistics content Explore R code from introductory slides   Activities  Review introductory statistics content  Chapters 2 - 4 of Statistical Reasoning through computation and R  Optional, complete course survey   Assignments None this week.\n ","date":1629331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629331200,"objectID":"1773d98851c0bab754bfb87807c55c10","permalink":"https://psqf6243.brandonlebeau.org/content/01-week1/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/content/01-week1/","section":"content","summary":"TBD","tags":null,"title":"Week 1","type":"book"},{"authors":null,"categories":null,"content":"   Introduction to Linear Regression This week will dive into linear regression, the foundation of this course. The exploration into linear regression will first start with the case when we have 2 continuous predictors or attributes. We may write this general model as:\n\\[ Y = \\beta_{0} + \\beta_{1} X + \\epsilon \\]\nWhere \\(Y\\) is the outcome attribute. It is also known as the dependent variable. The \\(X\\) term is the predictor/covariate attribute. It is also known as the independent variable. The \\(\\epsilon\\) is a random error term, more on this later. Finally, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are unknown population coefficients that we are interested in estimating. More on this later too.\nSpecific example The data used for this section of the course is from the 2019 WNBA season. These data are part of the bayesrules package/book. The data contain 146 rows, one for each WNBA player sampled, and 32 attributes for that player. The R packages are loaded and the first few rows of the data are shown below.\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.3 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 2.0.1 ✓ forcats 0.5.1 ## Warning: package \u0026#39;readr\u0026#39; was built under R version 4.1.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(mosaic) ## Registered S3 method overwritten by \u0026#39;mosaic\u0026#39;: ## method from ## fortify.SpatialPolygonsDataFrame ggplot2 ## ## The \u0026#39;mosaic\u0026#39; package masks several functions from core packages in order to add ## additional features. The original behavior of these functions should not be affected by this. ## ## Attaching package: \u0026#39;mosaic\u0026#39; ## The following object is masked from \u0026#39;package:Matrix\u0026#39;: ## ## mean ## The following objects are masked from \u0026#39;package:dplyr\u0026#39;: ## ## count, do, tally ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## cross ## The following object is masked from \u0026#39;package:ggplot2\u0026#39;: ## ## stat ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test, ## quantile, sd, t.test, var ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## max, mean, min, prod, range, sample, sum library(ggformula) basketball \u0026lt;- readr::read_csv(\u0026quot;https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/basketball.csv\u0026quot;) ## Rows: 146 Columns: 32 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (2): player_name, team ## dbl (29): height, weight, year, age, games_played, games_started, avg_minute... ## lgl (1): starter ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. theme_set(theme_bw(base_size = 18)) head(basketball) ## # A tibble: 6 × 32 ## player_name height weight year team age games_played games_started ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Natalie Achonwa 75 190 2019 IND 26 30 18 ## 2 Kayla Alexander 76 195 2019 CHI 28 3 0 ## 3 Rebecca Allen 74 162 2019 NYL 26 24 2 ## 4 Jillian Alleyne 74 193 2019 MIN 24 5 0 ## 5 Kristine Anigwe 76 200 2019 TOT 22 27 0 ## 6 Kristine Anigwe 76 200 2019 CON 22 17 0 ## # … with 24 more variables: avg_minutes_played \u0026lt;dbl\u0026gt;, avg_field_goals \u0026lt;dbl\u0026gt;, ## # avg_field_goal_attempts \u0026lt;dbl\u0026gt;, field_goal_pct \u0026lt;dbl\u0026gt;, ## # avg_three_pointers \u0026lt;dbl\u0026gt;, avg_three_pointer_attempts \u0026lt;dbl\u0026gt;, ## # three_pointer_pct \u0026lt;dbl\u0026gt;, avg_two_pointers \u0026lt;dbl\u0026gt;, ## # avg_two_pointer_attempts \u0026lt;dbl\u0026gt;, two_pointer_pct \u0026lt;dbl\u0026gt;, ## # avg_free_throws \u0026lt;dbl\u0026gt;, avg_free_throw_attempts \u0026lt;dbl\u0026gt;, free_throw_pct \u0026lt;dbl\u0026gt;, ## # avg_offensive_rb \u0026lt;dbl\u0026gt;, avg_defensive_rb \u0026lt;dbl\u0026gt;, avg_rb \u0026lt;dbl\u0026gt;, …  Guiding Question Suppose we are interested in exploring if players tend to score more points by playing more minutes in the season. That is, those that play more may have more opportunities to score more points. More generally, the relationship between average points in each game by the total minutes played across the season.\nOne first step in an analysis would be to explore each distribution independently first. I’m going to leave that as an exercise for you to do on your own.\nThe next step would be to explore the bivariate figure of these two attributes. As both of these attributes are continuous ratio type attributes, a scatterplot would be one way to visualize this. A scatterplot takes each X,Y pair of data and plots those coordinates. This can be done in R with the following code.\ngf_point(avg_points ~ total_minutes, data = basketball, size = 4, alpha = .5) %\u0026gt;% gf_labs(x = \u0026quot;Total Minutes Played\u0026quot;, y = \u0026quot;Average Points Scored\u0026quot;) cor(avg_points ~ total_minutes, data = basketball) ## [1] 0.8476624 Questions to consider What can be noticed about the relationship between these two attributes? Does there appear to be a relationship between the two? Is this relationship perfect?    Adding a smoother line Adding a smoother line to the figure can help to guide how strong the relationship may be. In general, there are two types of smoothers that we will consider in this course. One is flexible and data dependent. This means that the functional form of the relationship is flexible to allow the data to specify if there are in non-linear aspects. The second is a linear or straight-line approach.\nI’m going to add both to the figure below. The flexible (in this case this is a LOESS curve) curve is darker blue, the linear line is lighter blue.\nDoes there appear to be much difference in the relationship across the two lines?\ngf_point(avg_points ~ total_minutes, data = basketball, size = 4, alpha = .5) %\u0026gt;% gf_smooth() %\u0026gt;% gf_smooth(method = \u0026#39;lm\u0026#39;, linetype = 2, color = \u0026#39;lightblue\u0026#39;) %\u0026gt;% gf_labs(x = \u0026quot;Total Minutes Played\u0026quot;, y = \u0026quot;Average Points Scored\u0026quot;) ## `geom_smooth()` using method = \u0026#39;loess\u0026#39;  Estimating linear regression coefficients The linear regression coefficients can be estimated within any statistical software (or by hand, even if tedious). Within R, the primary function is lm() to estimate a linear regression. The primary argument is a formula similar to the regression formula shown above at the top of the notes.\nThis equation could be written more directly for our specific problem.\n\\[ Avg\\_points = \\beta_{0} + \\beta_{1} Minutes\\_Played + \\epsilon \\]\nFor the R formula, instead of an \\(=\\), you could insert a \\(~\\).\nwnba_reg \u0026lt;- lm(avg_points ~ total_minutes, data = basketball) coef(wnba_reg) ## (Intercept) total_minutes ## 1.13562456 0.01014207 \\[ Avg\\_points = 1.1356 + .0101 Minutes + \\epsilon \\]\n Interpretting linear regression terms Now that we have estimates for the linear regression terms, how are these interpretted? The linear regression equation with these estimates plugged in would look like the following:\n\\[ \\hat{avg\\_points} = 1.1356 + .0101 min\\_played \\]\nWhere instead of \\(\\beta_{0}\\) or \\(\\beta_{1}\\), the estimated values from this single season were inserted. Note the \\(\\hat{avg\\_points}\\), which the caret symbol is read as a hat, that is, average points hat, is a very important small distinction. This now represents the predicted values for the linear regression. That means, that the predicted value for the average number of points is assumed to function solely based on the minutes a player played. We could put in any value for the minutes played and get an estimated average number of points out.\n1.1356 + .0101 * 0 ## [1] 1.1356 1.1356 + .0101 * 1 ## [1] 1.1457 1.1356 + .0101 * 100 ## [1] 2.1456 1.1356 + .0101 * mean(basketball$total_minutes) ## [1] 5.342042 1.1356 + .0101 * 5000 ## [1] 51.6356 1.1356 + .0101 * -50 ## [1] 0.6306 Also notice from the equation above with the estimated coefficients, there is no longer any error. More on this later, but I wanted to point that out now. Back to model interpretations, these can become a bit more obvious with the values computed above by inputting specific values for the total minutes played.\nFirst, for the intercept (\\(\\beta_{0}\\)), notice that for the first computation above when 0 total minutes was input into the equation, that the same value for the intercept estimate was returned. This highlights what the intercept is, the average number of points scored when the X attribute (minutes played) equals 0.\nThe slope, (\\(\\beta_{1}\\)), term is the average change in the outcome (average points here) for a one unit change in the predictor attribute (minutes played). Therefore, the slope here is 0.0101, which means that the average points scores increases by about 0.01 points for every additional minute played. This effect is additive, meaning that the 0.01 for a one unit change, say from 100 to 101 minutes, will remain when increasing from 101 to 102 minutes.\nThe predictions coming from the linear regression are the same as the light blue dashed line shown in the figure above and recreated here without the dark blue line.\ngf_point(avg_points ~ total_minutes, data = basketball, size = 4, alpha = .5) %\u0026gt;% gf_smooth(method = \u0026#39;lm\u0026#39;, linetype = 2, color = \u0026#39;lightblue\u0026#39;) %\u0026gt;% gf_labs(x = \u0026quot;Total Minutes Played\u0026quot;, y = \u0026quot;Average Points Scored\u0026quot;)  What about the error? So far the error has been disregarded, but where did it go? The error didn’t disappear, it is actually in the figure just created above. Where can you see the error? Why was it disregarded when creating the predicted values?\nThe short answer is that the error in a linear regression is commonly assumed to follow a Normal distribution with a mean of 0 and some variance, \\(\\sigma^2\\). Sometimes this is written in math notation as:\n\\[ \\epsilon \\sim N(0, \\sigma^2) \\]\nFrom this notation, can you see why the error was disregarded earlier when generating predictions?\nIn short, on average, the error is assumed to be 0 across all the sample data. The error will be smaller when the data are more closely clustered around the linear regression line and larger when the data are not clustered around the linear regression line. In the simple case with a single predictor, the error would be minimized when the correlation is closest to 1 in absolute value and largest when the correlation close to or equals 0.\nEstimating error in linear regression This comes from partitioning of variance that you maybe heard from a design of experiment or analysis of variance course. More specifically, the variance in the outcome can be partioned or split into two components, those that the independent attribute helped to explain vs those that it can not explain. The part that can be explained is sometimes referred to as the sum of squares regression (SSR), the portion that is unexplained is referred to as the sum of squares error (SSE). This could be written in math notation as:\n\\[ \\sum (Y - \\bar{Y})^2 = \\sum (Y - \\hat{Y})^2 + \\sum (\\hat{Y} - \\bar{Y})^2 \\]\nLet’s try to visualize what this means.\ngf_point(avg_points ~ total_minutes, data = basketball, size = 4, alpha = .5) %\u0026gt;% gf_hline(yintercept = ~mean(avg_points), data = basketball) %\u0026gt;% gf_smooth(method = \u0026#39;lm\u0026#39;, linetype = 2, color = \u0026#39;lightblue\u0026#39;) %\u0026gt;% gf_segment(avg_points + mean(avg_points) ~ total_minutes + total_minutes, data = basketball, color = \u0026#39;#FF7F7F\u0026#39;) %\u0026gt;% gf_labs(x = \u0026quot;Total Minutes Played\u0026quot;, y = \u0026quot;Average Points Scored\u0026quot;) gf_point(avg_points ~ total_minutes, data = basketball, size = 4, alpha = .5) %\u0026gt;% gf_hline(yintercept = ~mean(avg_points), data = basketball) %\u0026gt;% gf_smooth(method = \u0026#39;lm\u0026#39;, linetype = 2, color = \u0026#39;lightblue\u0026#39;) %\u0026gt;% gf_segment(avg_points + fitted(wnba_reg) ~ total_minutes + total_minutes, data = basketball, color = \u0026#39;#65a765\u0026#39;) %\u0026gt;% gf_labs(x = \u0026quot;Total Minutes Played\u0026quot;, y = \u0026quot;Average Points Scored\u0026quot;) gf_point(avg_points ~ total_minutes, data = basketball, size = 4, alpha = .5) %\u0026gt;% gf_hline(yintercept = ~mean(avg_points), data = basketball) %\u0026gt;% gf_smooth(method = \u0026#39;lm\u0026#39;, linetype = 2, color = \u0026#39;lightblue\u0026#39;) %\u0026gt;% gf_segment(mean(avg_points) + fitted(wnba_reg) ~ total_minutes + total_minutes, data = basketball, color = \u0026#39;#FFD580\u0026#39;) %\u0026gt;% gf_labs(x = \u0026quot;Total Minutes Played\u0026quot;, y = \u0026quot;Average Points Scored\u0026quot;)   Another related measure of error Another way to get a measure of how well the model is performing, would be a statistic called R-squared. This statistic is a function of the sum of squares described above.\n\\[ R^{2} = 1 - \\frac{SS_{error}}{SS_{total}} \\]\nor\n\\[ R^{2} = \\frac{SS_{reg}}{SS_{total}} \\]\nLet’s compute the sum of square and get a value for \\(R^2\\).\nbasketball %\u0026gt;% summarise(ss_total = sum((avg_points - mean(avg_points))^2), ss_error = sum((avg_points - fitted(wnba_reg))^2), ss_reg = sum((fitted(wnba_reg) - mean(avg_points))^2)) %\u0026gt;% mutate(r_square = 1 - ss_error / ss_total, r_square2 = ss_reg / ss_total) ## # A tibble: 1 × 5 ## ss_total ss_error ss_reg r_square r_square2 ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2004. 564. 1440. 0.719 0.719 summary(wnba_reg)$r.square ## [1] 0.7185315 summary(wnba_reg)$sigma ## [1] 1.979045 sigma_hat_square \u0026lt;- 563.9929 / (nrow(basketball) - 2) sigma_hat \u0026lt;- sqrt(sigma_hat_square) sigma_hat_square ## [1] 3.916617 sigma_hat ## [1] 1.979045   ","date":1630368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630368000,"objectID":"76040bcec799399d6b4fe3b0eaae8738","permalink":"https://psqf6243.brandonlebeau.org/lectures/intro-regression/","publishdate":"2021-08-31T00:00:00Z","relpermalink":"/lectures/intro-regression/","section":"lectures","summary":"Linear Regression","tags":null,"title":"Intro to Linear Regression","type":"book"},{"authors":null,"categories":null,"content":"   Introduction This week is an introduction to linear regression. The primary goal of this week is to introduce the model and get familiar with the basic interpretation of parameters.\n Objectives  Recognize a linear regression formula Interpret regression parameters Specify a linear regression in statistical software   Activities  Read Chapter 1 of Applied Regression: An Introduction Engage with course notes. Optional, Read Chapter 7 of Statistical Reasoning through Computation and R Optional, Read 7.1 and 7.2 of Introduction to Modern Statistics   Assignments None this week.\n ","date":1630281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630281600,"objectID":"5f6df7af478d8d68bf48d6c7cb96efd6","permalink":"https://psqf6243.brandonlebeau.org/content/02-week2/","publishdate":"2021-08-30T00:00:00Z","relpermalink":"/content/02-week2/","section":"content","summary":"TBD","tags":null,"title":"Week 2","type":"book"},{"authors":null,"categories":null,"content":"   Understanding Regression Parameters This section of notes aims to dig a bit more into what the simple linear regression (ie., regression with a single continuous covariate) parameters mean. We will consider the estimation formulas in part of this to gain a sense of how these can be computed.\nNew Example Data The new data for this section of notes will explore data from the Environmental Protection Agency on Air Quality collected for the state of Iowa in 2021. The data are daily values for PM 2.5 particulates. The attributes included in the data are shown below with a short description.\n    Variable Description    date Date of observation  id Site ID  poc Parameter Occurrence Code (POC)  pm2.5 Average daily pm 2.5 particulate value, in (ug/m3; micrograms per meter cubed)  daily_aqi Average air quality index  site_name Site Name  aqs_parameter_desc Text Description of Observation  cbsa_code Core Based Statistical Area (CBSA) ID  cbsa_name CBSA Name  county County in Iowa  avg_wind Average daily wind speed (in knots)  max_wind Maximum daily wind speed (in knots)  max_wind_hours Time of maximum daily wind speed    Guiding Question How is pm2.5 related to the daily air quality index?\n  Bivariate Figure Note, below I do a bit of post-processing to combine data from different POC values within a single CBSA.\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.3 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 2.0.1 ✓ forcats 0.5.1 ## Warning: package \u0026#39;readr\u0026#39; was built under R version 4.1.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(ggformula) ## Loading required package: ggstance ## ## Attaching package: \u0026#39;ggstance\u0026#39; ## The following objects are masked from \u0026#39;package:ggplot2\u0026#39;: ## ## geom_errorbarh, GeomErrorbarh ## Loading required package: scales ## ## Attaching package: \u0026#39;scales\u0026#39; ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## discard ## The following object is masked from \u0026#39;package:readr\u0026#39;: ## ## col_factor ## Loading required package: ggridges ## ## New to ggformula? Try the tutorials: ## learnr::run_tutorial(\u0026quot;introduction\u0026quot;, package = \u0026quot;ggformula\u0026quot;) ## learnr::run_tutorial(\u0026quot;refining\u0026quot;, package = \u0026quot;ggformula\u0026quot;) library(mosaic) ## Registered S3 method overwritten by \u0026#39;mosaic\u0026#39;: ## method from ## fortify.SpatialPolygonsDataFrame ggplot2 ## ## The \u0026#39;mosaic\u0026#39; package masks several functions from core packages in order to add ## additional features. The original behavior of these functions should not be affected by this. ## ## Attaching package: \u0026#39;mosaic\u0026#39; ## The following object is masked from \u0026#39;package:Matrix\u0026#39;: ## ## mean ## The following object is masked from \u0026#39;package:scales\u0026#39;: ## ## rescale ## The following objects are masked from \u0026#39;package:dplyr\u0026#39;: ## ## count, do, tally ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## cross ## The following object is masked from \u0026#39;package:ggplot2\u0026#39;: ## ## stat ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test, ## quantile, sd, t.test, var ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## max, mean, min, prod, range, sample, sum theme_set(theme_bw(base_size = 18)) airquality \u0026lt;- readr::read_csv(\u0026quot;https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/iowa_air_quality_2021.csv\u0026quot;) ## Rows: 6917 Columns: 10 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (5): date, site_name, aqs_parameter_desc, cbsa_name, county ## dbl (5): id, poc, pm2.5, daily_aqi, cbsa_code ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. wind \u0026lt;- readr::read_csv(\u0026quot;https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/daily_WIND_2021-iowa.csv\u0026quot;) ## Rows: 1537 Columns: 5 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (2): date, cbsa_name ## dbl (3): avg_wind, max_wind, max_wind_hours ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. airquality \u0026lt;- airquality %\u0026gt;% left_join(wind, by = c(\u0026#39;cbsa_name\u0026#39;, \u0026#39;date\u0026#39;)) %\u0026gt;% drop_na() head(airquality) ## # A tibble: 6 × 13 ## date id poc pm2.5 daily_aqi site_name aqs_parameter_d… cbsa_code ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1/1/21 190130009 1 15.1 57 Water Tower PM2.5 - Local C… 47940 ## 2 1/4/21 190130009 1 13.3 54 Water Tower PM2.5 - Local C… 47940 ## 3 1/7/21 190130009 1 20.5 69 Water Tower PM2.5 - Local C… 47940 ## 4 1/10/21 190130009 1 14.3 56 Water Tower PM2.5 - Local C… 47940 ## 5 1/13/21 190130009 1 13.7 54 Water Tower PM2.5 - Local C… 47940 ## 6 1/16/21 190130009 1 5.3 22 Water Tower PM2.5 - Local C… 47940 ## # … with 5 more variables: cbsa_name \u0026lt;chr\u0026gt;, county \u0026lt;chr\u0026gt;, avg_wind \u0026lt;dbl\u0026gt;, ## # max_wind \u0026lt;dbl\u0026gt;, max_wind_hours \u0026lt;dbl\u0026gt; dim(airquality) ## [1] 4821 13 gf_point(daily_aqi ~ avg_wind, data = airquality, size = 4, alpha = .15) %\u0026gt;% gf_labs(x = \u0026quot;Average daily wind speed (in knots)\u0026quot;, y = \u0026quot;Daily Air Quality\u0026quot;) %\u0026gt;% gf_smooth() %\u0026gt;% gf_smooth(method = \u0026#39;lm\u0026#39;, color = \u0026#39;lightblue\u0026#39;, linetype = 2) ## `geom_smooth()` using method = \u0026#39;gam\u0026#39; cor(daily_aqi ~ avg_wind, data = airquality) ## [1] -0.2920277 air_lm \u0026lt;- lm(daily_aqi ~ avg_wind, data = airquality) coef(air_lm) ## (Intercept) avg_wind ## 48.222946 -2.211798 summary(air_lm)$r.square ## [1] 0.08528019 summary(air_lm)$sigma ## [1] 18.05479  Centering predictors There are times when centering of predictors can be helpful for interpretation of the model parameters. This can be helpful when 0 is not a practically useful characteristic of the attribute or for more specific tests of certain elements of the X attribute.\nMean Centering Mean centering is where the mean of the attribute is subtracted from each value. This is a linear transformation where each data point is subtracted by a constant, the mean. This means that the distance between points do not change.\nairquality \u0026lt;- airquality %\u0026gt;% mutate(avg_wind_mc = avg_wind - mean(avg_wind), avg_wind_maxc = avg_wind - max(avg_wind), avg_wind_10 = avg_wind - 10) gf_point(daily_aqi ~ avg_wind_mc, data = airquality, size = 4, alpha = .15) %\u0026gt;% gf_labs(x = \u0026quot;Average daily wind speed (in knots)\u0026quot;, y = \u0026quot;Daily Air Quality\u0026quot;) %\u0026gt;% gf_smooth() %\u0026gt;% gf_smooth(method = \u0026#39;lm\u0026#39;, color = \u0026#39;lightblue\u0026#39;, linetype = 2) ## `geom_smooth()` using method = \u0026#39;gam\u0026#39; air_lm_mc \u0026lt;- lm(daily_aqi ~ avg_wind_mc, data = airquality) coef(air_lm_mc) ## (Intercept) avg_wind_mc ## 38.788011 -2.211798 summary(air_lm_mc)$r.square ## [1] 0.08528019 summary(air_lm_mc)$sigma ## [1] 18.05479 air_lm_maxc \u0026lt;- lm(daily_aqi ~ avg_wind_maxc, data = airquality) coef(air_lm_maxc) ## (Intercept) avg_wind_maxc ## 5.968391 -2.211798 summary(air_lm_maxc)$r.square ## [1] 0.08528019 summary(air_lm_maxc)$sigma ## [1] 18.05479 air_lm_10 \u0026lt;- lm(daily_aqi ~ avg_wind_10, data = airquality) coef(air_lm_10) ## (Intercept) avg_wind_10 ## 26.104968 -2.211798 summary(air_lm_10)$r.square ## [1] 0.08528019 summary(air_lm_10)$sigma ## [1] 18.05479   Standardized Regression Another type of regression that can be done is one in which the attributes are standardized prior to estimating the linear regression. What is meant by standardizing? This is converting the attributes into z-scores:\n\\[ Z_{api} = \\frac{(aqi - \\bar{aqi})}{s_{aqi}} \\]\nairquality \u0026lt;- airquality %\u0026gt;% mutate(z_aqi = scale(daily_aqi), z_aqi2 = (daily_aqi - mean(daily_aqi)) / sd(daily_aqi), z_wind = scale(avg_wind)) head(airquality) ## # A tibble: 6 × 19 ## date id poc pm2.5 daily_aqi site_name aqs_parameter_d… cbsa_code ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1/1/21 190130009 1 15.1 57 Water Tower PM2.5 - Local C… 47940 ## 2 1/4/21 190130009 1 13.3 54 Water Tower PM2.5 - Local C… 47940 ## 3 1/7/21 190130009 1 20.5 69 Water Tower PM2.5 - Local C… 47940 ## 4 1/10/21 190130009 1 14.3 56 Water Tower PM2.5 - Local C… 47940 ## 5 1/13/21 190130009 1 13.7 54 Water Tower PM2.5 - Local C… 47940 ## 6 1/16/21 190130009 1 5.3 22 Water Tower PM2.5 - Local C… 47940 ## # … with 11 more variables: cbsa_name \u0026lt;chr\u0026gt;, county \u0026lt;chr\u0026gt;, avg_wind \u0026lt;dbl\u0026gt;, ## # max_wind \u0026lt;dbl\u0026gt;, max_wind_hours \u0026lt;dbl\u0026gt;, avg_wind_mc \u0026lt;dbl\u0026gt;, ## # avg_wind_maxc \u0026lt;dbl\u0026gt;, avg_wind_10 \u0026lt;dbl\u0026gt;, z_aqi \u0026lt;dbl[,1]\u0026gt;, z_aqi2 \u0026lt;dbl\u0026gt;, ## # z_wind \u0026lt;dbl[,1]\u0026gt; air_lm_s \u0026lt;- lm(z_aqi ~ z_wind, data = airquality) coef(air_lm_s) ## (Intercept) z_wind ## -2.113006e-15 -2.920277e-01 summary(air_lm_s)$r.square ## [1] 0.08528019 summary(air_lm_s)$sigma ## [1] 0.9565091 We can also use this formula to convert any unstandardized regression coefficients into a standardized metric.\n\\[ b^{\u0026#39;}_{k} = b_{k} * \\frac{s_{x_{k}}}{s_{y}} \\]\n-2.211 * sd(airquality$avg_wind) / sd(airquality$daily_aqi) ## [1] -0.2919224 cor(daily_aqi ~ avg_wind, data = airquality) ## [1] -0.2920277  Parameter Estimation Now that we looked how the parameters are impacted by some changes in the model specification, how are these parameters actually estimated? I will show two ways, one is general, the other is specific to this simple case with a single predictor/covariate attribute. In general, linear regression (or more generally the general linear model) uses least square estimation. This means that the the parameters in the model minimize the squared distance between the observed and predicted values. That is, least squares estimates minimize this criterion:\n\\[ \\sum (Y - \\hat{Y})^2 \\]\nSpecific example Calculus can be used to show that these two equations can be solved simultanuously to get estimates for \\(\\beta_{0}\\) and \\(\\beta_{1}\\) that minimize the criterion above. These formulas are:\n\\[ b_{1} = \\frac{\\sum(X - \\bar{X})(Y - \\bar{Y})}{\\sum(X - \\bar{X})^2} \\] \\[ b_{0} = \\bar{Y} - b_{1}\\bar{X} \\]\nLet’s use R to get these quantities.\nb1 \u0026lt;- with(airquality, sum((avg_wind - mean(avg_wind)) * (daily_aqi - mean(daily_aqi))) / sum((avg_wind - mean(avg_wind))^2) ) b0 \u0026lt;- with(airquality, mean(daily_aqi) - b1 * mean(avg_wind) ) b0 ## [1] 48.22295 b1 ## [1] -2.211798 coef(air_lm) ## (Intercept) avg_wind ## 48.222946 -2.211798  General Approach When there are more than one predictor, the number of equations gets a bit unyieldy, therefore, there is a general analytic approach that works for any set of predictor attributes. The general approach uses matrix algebra (anyone take linear algebra?), to achieve their estimates. This general form is:\n\\[ \\mathbf{b} = \\left( \\mathbf{X}^{`}\\mathbf{X} \\right)^{-1} \\left( \\mathbf{X}^{`} \\mathbf{Y} \\right). \\] Where \\(\\mathbf{b}\\) is a vector of estimated regression coefficients, \\(\\mathbf{X}\\) is a matrix of covariate/predictor attributes (called the design matrix), and \\(\\mathbf{Y}\\) is a vector of the outcome attribute.\nBelow, I show what these would look like for the air quality example that has been used and solve for the regression coefficients.\nX \u0026lt;- model.matrix(air_lm) head(X) ## (Intercept) avg_wind ## 1 1 2.941667 ## 2 1 2.445833 ## 3 1 1.995833 ## 4 1 3.445833 ## 5 1 1.116667 ## 6 1 6.091667 Y \u0026lt;- as.matrix(airquality$daily_aqi) head(Y) ## [,1] ## [1,] 57 ## [2,] 54 ## [3,] 69 ## [4,] 56 ## [5,] 54 ## [6,] 22 X_X \u0026lt;- solve(t(X) %*% X) X_X ## (Intercept) avg_wind ## (Intercept) 0.0008152474 -1.424894e-04 ## avg_wind -0.0001424894 3.340328e-05 X_Y \u0026lt;- t(X) %*% Y X_Y ## [,1] ## (Intercept) 186997 ## avg_wind 731464 X_X %*% X_Y ## [,1] ## (Intercept) 48.222946 ## avg_wind -2.211798 coef(air_lm) ## (Intercept) avg_wind ## 48.222946 -2.211798    ","date":1630540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630540800,"objectID":"c4fb6591bac1c6b88503b9ea8067003b","permalink":"https://psqf6243.brandonlebeau.org/lectures/regression-estimates/","publishdate":"2021-09-02T00:00:00Z","relpermalink":"/lectures/regression-estimates/","section":"lectures","summary":"Linear Regression Estimates'","tags":null,"title":"Linear Regression Estimates","type":"book"}]